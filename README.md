# ğŸ§ ğŸ™ï¸ Voice-Controlled Agentic AI Bot

A real-time voice assistant powered by **Ollama**, **Piper TTS**, and **SpeechRecognition**. This agent listens to voice input, processes it using an LLM, and responds back with natural synthesized speech.

---

## ğŸš€ Features

- ğŸ¤ Real-time voice input using `SpeechRecognition`
- ğŸ§  LLM-powered response generation with [`Ollama`](https://ollama.com/)
- ğŸ”Š Text-to-speech output via `Piper`
- ğŸ§µ Multi-threaded performance for responsiveness
- ğŸ§  Maintains short-term conversation context

---

## ğŸ› ï¸ Tech Stack

| Component        | Tech                          |
|------------------|-------------------------------|
| Language Model   | `Ollama` (e.g., gemma, deepseek) |
| Voice Recognition| `speech_recognition` + Google API |
| Text-to-Speech   | [`Piper`](https://github.com/rhasspy/piper) |
| Backend Threads  | `Python`, `Threading`         |

---

## ğŸ“¦ Installation

```bash
# Clone the repo
git clone https://github.com/alihassanml/Voice-Controlled-Agentic-AI-Bot.git
cd Voice-Controlled-Agentic-AI-Bot

# (Optional) Create a virtual environment
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows

# Install dependencies
pip install -r requirements.txt
```

---

## ğŸ§ª Run the Bot

> Ensure Ollama is running locally and a model (e.g., `gemma:2b`) is pulled.

```bash
# Start your local Ollama instance
ollama serve

# Pull a model
ollama pull gemma:2b

# Run the bot
python app.py
```

---

## ğŸ“ Directory Structure

```
ğŸ“¦ Voice-Controlled-Agentic-AI-Bot
â”œâ”€â”€ piper/                         # Piper TTS binary and models
â”œâ”€â”€ output.mp3                     # TTS output file
â”œâ”€â”€ app.py                         # Main application
â”œâ”€â”€ requirements.txt               # Python dependencies
â””â”€â”€ README.md                      # Project documentation
```

---

## ğŸ”Š Voice Models

Download Piper models from: [https://huggingface.co/rhasspy/piper-voices](https://huggingface.co/rhasspy/piper-voices)

Recommended: `en_US-kristin-medium.onnx`

Place the `.onnx` model under `piper/model/`.

---

## ğŸ§  Example Interaction

```text
ğŸ¤ Listening...

ğŸ—£ User: What's the weather in Paris today?
ğŸ¤– AI: I'm not connected to real-time data, but Paris is typically mild in April.
```

---

## ğŸ“Œ To-Do / Enhancements

- [ ] Add wake word detection
- [ ] Integrate GUI interface
- [ ] Add multi-language support
- [ ] Improve context memory window

---

## ğŸ‘¨â€ğŸ’» Author

**Ali Hassan**  
[GitHub](https://github.com/alihassanml) | [LinkedIn](https://linkedin.com/in/alihassanml)

---

## ğŸªª License

MIT License â€“ use freely, give credit!
